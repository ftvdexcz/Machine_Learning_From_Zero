{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ccf5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a85f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#1 Constant trong tensorflow\n",
    "x = tf.constant(5,tf.float32)\n",
    "y = tf.constant([5], tf.float32)\n",
    "z = tf.constant([5,3,4], tf.float32)\n",
    "t = tf.constant([[5,3,4,6],[2,3,4,7]], tf.float32)\n",
    "u = tf.constant([[[5,3,4,6],[2,3,4,0]]], tf.float32)\n",
    "v = tf.constant([[[5,3,4,6],[2,3,4,0]],\n",
    " [[5,3,4,6],[2,3,4,0]],\n",
    "[[5,3,4,6],[2,3,4,0]]\n",
    " ], tf.float32)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4711ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.79\n"
     ]
    }
   ],
   "source": [
    "#2. Variable trong tensorflow\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "x1 = tf.Variable(5.3, tf.float32)\n",
    "x2 = tf.Variable(4.3, tf.float32)\n",
    "x = tf.multiply(x1,x2)\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init) \n",
    "    t = sess.run(x)\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a11bbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.79 19.35 42.  ]\n",
      " [22.79 19.35 42.  ]]\n"
     ]
    }
   ],
   "source": [
    "#3. Placeholder\n",
    "x1 = tf.Variable([[5.3,4.5,6.0],\n",
    " [4.3,4.3,7.0]\n",
    " ], tf.float32)\n",
    "x2 = tf.Variable([[4.3,4.3,7.0],\n",
    " [5.3,4.5,6.0]\n",
    " ], tf.float32)\n",
    "x = tf.multiply(x1,x2)\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    t = sess.run(x)\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3d43ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.compat.v1.placeholder(tf.float32,None)\n",
    "y = tf.add(x,x)\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    x_data= 5\n",
    "    result = sess.run(y,feed_dict={x:x_data})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8ba95c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98856974\n"
     ]
    }
   ],
   "source": [
    "# 4. Operation\n",
    "x1 = tf.constant(5.3, tf.float32)\n",
    "x2 = tf.constant(1.5, tf.float32)\n",
    "w1 = tf.Variable(0.7, tf.float32)\n",
    "w2 = tf.Variable(0.5, tf.float32)\n",
    "u = tf.multiply(x1,w1)\n",
    "v = tf.multiply(x2,w2)\n",
    "z = tf.add(u,v)\n",
    "result = tf.sigmoid(z)\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f60d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28717b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 207us/sample - loss: 0.6937 - accuracy: 0.5010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 27us/sample - loss: 0.6935 - accuracy: 0.5010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.6933 - accuracy: 0.5040\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.6933 - accuracy: 0.5050\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.6932 - accuracy: 0.5020\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.6932 - accuracy: 0.5050\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.6931 - accuracy: 0.4970\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.6931 - accuracy: 0.4960\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 0.6931 - accuracy: 0.5090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ftvde\\Envs\\dltf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# Getting the data ready\n",
    "# Generate train dummy data for 1000 Students and dummy testfor 500\n",
    "#Columns :Age, Hours of Study &Avg Previous test scores\n",
    "np.random.seed(2018) #Setting seed for reproducibility\n",
    "train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))\n",
    "#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "#Defining the model structure with the required layers, \n",
    "# ofneurons, activation function and optimizers\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(5, input_dim=3, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "#Train the model and make predictions\n",
    "model.fit(train_data, labels, epochs=10, batch_size=32)\n",
    "#Make predictions from the trained model\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6ca6cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "6000/6000 [==============================] - 1s 130us/sample - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6929 - val_accuracy: 0.5025\n",
      "Epoch 2/3\n",
      "2944/6000 [=============>................] - ETA: 0s - loss: 0.6929 - accuracy: 0.5088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ftvde\\Envs\\dltf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 29us/sample - loss: 0.6927 - accuracy: 0.5097 - val_loss: 0.6927 - val_accuracy: 0.5040\n",
      "Epoch 3/3\n",
      "6000/6000 [==============================] - 0s 39us/sample - loss: 0.6928 - accuracy: 0.5040 - val_loss: 0.6926 - val_accuracy: 0.5150\n",
      "[0.6936473646163941, 0.4895]\n",
      "['loss', 'accuracy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.50445694],\n",
       "       [0.50903684],\n",
       "       [0.5098993 ],\n",
       "       [0.49688494],\n",
       "       [0.5064239 ],\n",
       "       [0.50283027],\n",
       "       [0.4939661 ],\n",
       "       [0.5023024 ],\n",
       "       [0.5032323 ],\n",
       "       [0.50579613]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dummy training dataset\n",
    "np.random.seed(2018)\n",
    "x_train = np.random.random((6000,10))\n",
    "y_train = np.random.randint(2, size=(6000, 1))\n",
    "# Generate dummy validation dataset\n",
    "x_val = np.random.random((2000,10))\n",
    "y_val = np.random.randint(2, size=(2000, 1))\n",
    "# Generate dummy test dataset\n",
    "x_test = np.random.random((2000,10))\n",
    "y_test = np.random.randint(2, size=(2000, 1))\n",
    "#Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(64, input_dim=10,activation = \"relu\")) #Layer 1\n",
    "model.add(layers.Dense(32,activation = \"relu\")) #Layer 2\n",
    "model.add(layers.Dense(16,activation = \"relu\")) #Layer 3\n",
    "model.add(layers.Dense(8,activation = \"relu\")) #Layer 4\n",
    "model.add(layers.Dense(4,activation = \"relu\")) #Layer 5\n",
    "model.add(layers.Dense(1,activation = \"sigmoid\")) #OutputLayer\n",
    "#Configure the model\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics =['accuracy'])\n",
    "#Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3, \n",
    "validation_data=(x_val,y_val))\n",
    "#evaluate(x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)\n",
    "print(model.evaluate(x_test,y_test)) \n",
    "print(model.metrics_names)\n",
    "#print 10 predictions\n",
    "pred = model.predict(x_test)\n",
    "pred[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f852a20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/15\n",
      "1000/1000 [==============================] - 0s 221us/sample - loss: 0.6876 - accuracy: 0.5560\n",
      "Epoch 2/15\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.6875 - accuracy: 0.5560\n",
      "Epoch 3/15\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 0.6874 - accuracy: 0.5560\n",
      "Epoch 4/15\n",
      "1000/1000 [==============================] - 0s 83us/sample - loss: 0.6874 - accuracy: 0.5560\n",
      "Epoch 5/15\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.6875 - accuracy: 0.5560\n",
      "Epoch 6/15\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 0.6875 - accuracy: 0.5560\n",
      "Epoch 7/15\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.6873 - accuracy: 0.5560\n",
      "Epoch 8/15\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.6872 - accuracy: 0.5560\n",
      "Epoch 9/15\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.6872 - accuracy: 0.5560\n",
      "Epoch 10/15\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.6872 - accuracy: 0.5560\n",
      "Epoch 11/15\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.6872 - accuracy: 0.5560\n",
      "Epoch 12/15\n",
      "1000/1000 [==============================] - 0s 28us/sample - loss: 0.6871 - accuracy: 0.5560\n",
      "Epoch 13/15\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.6872 - accuracy: 0.5560\n",
      "Epoch 14/15\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.6871 - accuracy: 0.5560\n",
      "Epoch 15/15\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.6870 - accuracy: 0.5560\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np\n",
    "#Generate dummy data for 3 features and 1000 samples\n",
    "x_train = np.random.random((1000, 3))\n",
    "#Generate dummy results for 1000 samples: 1 or 0\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "#Create a python function that returns a compiled DNN model\n",
    "def create_dnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(12, input_dim=3, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "    return model\n",
    "#Use Keras wrapper to package the model as an sklearn object\n",
    "model = KerasClassifier(build_fn=create_dnn_model)\n",
    "# define the grid search parameters\n",
    "batch_size = [32,64,128]\n",
    "epochs = [15, 30, 60]\n",
    "#Create a list with the parameters\n",
    "param_grid = {\"batch_size\":batch_size, \"epochs\":epochs}\n",
    "#Invoke the grid search method with the list of hyperparameters\n",
    "grid_model = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "#Train the model\n",
    "grid_model.fit(x_train, y_train)\n",
    "#Extract the best model grid search\n",
    "best_model = grid_model.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dltf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8bfa77255f69f75ac2d60861a03a716e802c50d0b09af27f4d2216c2b2415e22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
